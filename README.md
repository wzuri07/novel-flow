# üìñ Novel Flow ‚Äî AI-Powered Chinese Web Novel Reader

A personal PWA (Progressive Web App) that fetches chapters from [lnmtl.com](https://lnmtl.com), extracts the machine-translated text, and polishes it using a local AI (Ollama) or Google Gemini API ‚Äî so you can actually enjoy reading Chinese web novels in English.

---

## ‚ú® Features

- üì• Fetch any chapter directly from lnmtl.com by pasting the URL
- ü§ñ AI grammar smoothing via **Ollama** (local, free, private) or **Google Gemini** (fast, free tier)
- üîÑ Streaming output ‚Äî text appears as it's generated, no waiting for the full chapter
- üìñ Clean reader interface with dark/light mode
- üî§ Adjustable font size
- ‚¨ÖÔ∏è ‚û°Ô∏è Previous / Next chapter navigation
- üì± Installable as a PWA on Android and iOS
- üîí 100% private ‚Äî all processing happens on your own PC

---

## üõ†Ô∏è Tech Stack

- **Frontend:** React + TypeScript + Vite + Tailwind CSS + shadcn/ui
- **AI (local):** Ollama running Gemma3 locally on your PC
- **AI (cloud):** Google Gemini API (free tier)
- **CORS Proxy:** local-cors-proxy (runs on your PC)
- **Remote access:** Tailscale (access from phone anywhere)
- **Hosting:** GitHub Pages (UI only)

---

## üöÄ How It Works

```
Your Phone / Browser
        ‚Üì
  React PWA (GitHub Pages or local)
        ‚Üì
  Local CORS Proxy (port 8010) ‚Üí lnmtl.com chapter
        ‚Üì
  Ollama (port 11434) or Gemini API
        ‚Üì
  Smoothed, clean English text displayed in reader
```

---

## ‚öôÔ∏è Setup

### Prerequisites

- [Node.js](https://nodejs.org) (LTS version)
- [Ollama](https://ollama.com) installed on your PC
- [Tailscale](https://tailscale.com) (optional, for phone access from anywhere)

### Installation

```bash
# Clone the repo
git clone https://github.com/wzuri07/novel-flow.git
cd novel-flow

# Install dependencies
npm install

# Install the CORS proxy globally
npm install -g local-cors-proxy
```

### Pull an AI model

```bash
ollama pull gemma3:12b   # High quality, slower (recommended for 16GB+ RAM)
ollama pull gemma3:4b    # Faster, good quality (recommended for 8GB RAM)
```

### Start everything

Either run the batch file (Windows):

```
novel-reader-start.bat
```

Or manually in separate terminals:

```bash
# Terminal 1 ‚Äî Start Ollama
set OLLAMA_ORIGINS=*
set OLLAMA_HOST=0.0.0.0:11434
ollama serve

# Terminal 2 ‚Äî Start CORS proxy
lcp --proxyUrl https://lnmtl.com --port 8010 --proxyPartial proxy

# Terminal 3 ‚Äî Start the app
npm run dev
```

Then open your browser at:
```
http://localhost:8080
```

---

## üì± Phone Access

1. Install [Tailscale](https://tailscale.com) on both your PC and phone
2. Sign in with the same account on both
3. Find your PC's Tailscale IP (e.g. `100.x.x.x`)
4. Open `http://100.x.x.x:8080` on your phone browser
5. Tap **Add to Home Screen** to install as a PWA

---

## ‚öôÔ∏è Settings

Click the gear icon ‚öôÔ∏è in the top right to configure:

| Setting | Default | Description |
|---|---|---|
| Ollama API URL | `http://100.x.x.x:11434` | Your local Ollama endpoint |
| Model Name | `gemma3:12b` | Any Ollama model you have pulled |
| CORS Proxy URL | `http://100.x.x.x:8010/proxy` | Local proxy for fetching lnmtl.com |
| Gemini API Key | *(empty)* | Optional ‚Äî get free key at aistudio.google.com |
| AI Provider | Ollama | Toggle between Ollama and Gemini |

---

## üÜì Cost

**Everything is free.**

| Component | Cost |
|---|---|
| Ollama + models | Free |
| GitHub Pages hosting | Free |
| local-cors-proxy | Free |
| Tailscale personal | Free |
| Gemini API (free tier) | Free (1,500 requests/day) |

---

## üìù Notes

- This app is for **personal use only**
- Your PC must be on and running for the app to work
- The batch file can be placed in your Windows startup folder to auto-start everything on boot
- GitHub Pages version is for reference only ‚Äî use the local version at `http://localhost:8080` for full functionality

---

## üôè Credits

Built with [Lovable](https://lovable.dev), [Ollama](https://ollama.com), and [Google Gemini](https://aistudio.google.com).

---

## üß© Beginner Chrome Extension (Optional)

If you want a browser sidebar workflow instead of the full PWA, a ready-to-load Chrome extension scaffold is included in `lnmt-ai-reader/`.

### Extension features

- Opens a Chrome side panel from the toolbar button
- Extracts visible chapter text from `lnmtl.com`
- Sends chapter text to OpenAI for grammar/readability cleanup
- Renders improved text in the side panel
- Stores API key locally with `chrome.storage.local`

### Load it in Chrome

1. Open `chrome://extensions/`
2. Enable **Developer mode**
3. Click **Load unpacked**
4. Select the `lnmt-ai-reader` folder from this repo

> ‚ö†Ô∏è Keep in mind this extension sends chapter text to OpenAI APIs and stores your API key in your local browser profile.
